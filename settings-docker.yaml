server:
  env_name: ${APP_ENV:docker}
  port: ${PORT:8080}

llm:
  mode: ${PGPT_INFERENCE_MODE:openai}

embedding:
  mode: ${PGPT_EMBEDDING_MODE:openai}

local:
  llm_hf_repo_id: ${PGPT_HF_REPO_ID:TheBloke/Mistral-7B-Instruct-v0.1-GGUF}
  llm_hf_model_file: ${PGPT_HF_MODEL_FILE:mistral-7b-instruct-v0.1.Q4_K_M.gguf}
  embedding_hf_model_name: ${PGPT_EMBEDDING_HF_MODEL_NAME:BAAI/bge-small-en-v1.5}

ui:
  enabled: true
  path: /

qdrant:
  url: ${QDRANT_URL:}
  api_key: ${QDRANT_API_KEY:}

openai:
  api_key: ${OPENAI_API_KEY:}
  model: ${OPENAI_MODEL:gpt-3.5-turbo}
