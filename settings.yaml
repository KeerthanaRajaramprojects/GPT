server:
  env_name: ${APP_ENV:prod}
  port: ${PORT:8001}

ui:
  enabled: true
  path: /

llm:
  default_llm: mock

local_llm:
  enabled: false
  model_name: llama-2-7b-chat.Q4_0.gguf

sagemaker:
  enabled: false
  endpoint_name: huggingface-pytorch-tgi-inference-2023-09-25-19-53-32-140

openai:
  enabled: false
  api_key: ${OPENAI_API_KEY:}
